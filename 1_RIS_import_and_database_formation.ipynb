{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code performs a search for scientific articles related to the topic of \"p-graph\" or \"process graph theory\" using the Scopus API. Alternatively, it can import RIS files from a specified folder to create a Pandas dataframe containing information about the articles.\n",
    "1. The ScopusSearch function from the pybliometrics.scopus module is used to perform the search. The 'view' parameter can be used to set the number of headers to be retrieved, and the search query is specified as a string in the function call.\n",
    "2. The RIS files import process involves setting the folder path, obtaining a list of RIS files in the folder, creating an empty list to hold the dictionaries for each article, and then iterating through each file, converting it into a dictionary, and appending it to the list of dictionaries. A Pandas dataframe is then created from this list of dictionaries.\n",
    "3. Once the SLR results dataframe is created, the code can extract information such as the dimensions and list of headers using the shape and columns.tolist() functions, respectively. It can also write the data to an Excel file for easier readability using the to_excel function from the pandas module.\n",
    "4. An optional step involves sorting the dataframe by keywords defined based on previous knowledge. This is done by creating a new filtered dataframe using the str.contains function to search for specific keywords in the title, abstract, and keywords fields. The filtered dataframe is also written to an Excel file for easier readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pybliometrics\n",
    "import rispy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scopus search -> Performs a query to search for articles\n",
    "# Any search that works in the Scopus website's Advanced Search function can be recreated.\n",
    "# There are two exceptions: LIMIT-TO() -> only affects the display of search results | INDEXTERMS()\n",
    "\n",
    "from pybliometrics.scopus import ScopusSearch\n",
    "search = ScopusSearch('TITLE (\"p-graph\" OR \"p graph\" OR \"process graph theory\") OR KEY(\"p-graph\")', view=\"COMPLETE\")\n",
    "# Within the function, the \"view\" parameter can be used to set the number of headers (Complete contains 36 variables). This must match our own database or at least the imported data.\n",
    "# Attention: Scopus API functions may require a registered licence, including a generated API key (https://dev.elsevier.com/). Only 5000 articles can be queried in the free version, unlimited for paying users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported all RIS files!\n"
     ]
    }
   ],
   "source": [
    "# Alternatively, import .RIS files exported from the scientific database (e.g. Scopus, WoS) from a specified folder (file path) to a Pandas dataframe (df)\n",
    "# set the path to the folder containing the RIS files\n",
    "folder_path = 'C:/Users/<filepath>'\n",
    "\n",
    "# get a list of all the .RIS files in the folder\n",
    "ris_files = [f for f in os.listdir(folder_path) if f.endswith('.ris')]\n",
    "\n",
    "# create an empty list to hold the dictionaries for each article\n",
    "articles = []\n",
    "\n",
    "# loop through each RIS file, import it into a dictionary, and append it to the list of dictionaries\n",
    "for file in ris_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    with open(file_path, \"r\", encoding=\"UTF-8\") as f:\n",
    "        entries = rispy.load(f)\n",
    "        for entry in entries:\n",
    "            articles.append(entry)\n",
    "\n",
    "# create a pandas dataframe from the list of dictionaries\n",
    "slr_results = pd.DataFrame(articles)\n",
    "\n",
    "print(\"Successfully imported all RIS files!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    type_of_reference                                              title  \\\n",
      "0                JOUR  Addressing supply uncertainties using multi-pe...   \n",
      "1                JOUR  Synthesis of multiperiod heat exchanger networ...   \n",
      "2                JOUR  Optimisation of heat distribution system by us...   \n",
      "3                JOUR  General formulation of resilience for designin...   \n",
      "4                JOUR  P-graph optimization of energy crisis response...   \n",
      "..                ...                                                ...   \n",
      "289              JOUR  Applications of P-graph to Carbon Management: ...   \n",
      "290              JOUR  P-graph Attainable Region Technique (PART) for...   \n",
      "291              JOUR  Framework to embed machine learning algorithms...   \n",
      "292              JOUR  Enabling technology models with nonlinearities...   \n",
      "293              JOUR  Synthesis of mass exchange network using proce...   \n",
      "\n",
      "                                               authors  \\\n",
      "0    [Lo, S.L.Y., Lim, C.H., Benjamin, M.F.D., Lam,...   \n",
      "1     [Lakner, R., Orosz, Á., How, B.S., Friedler, F.]   \n",
      "2        [Kuznetsov, M., Tsibulsky, S., Boldyryev, S.]   \n",
      "3    [Orosz, Á., Pimentel, J., Argoti, A., Friedler...   \n",
      "4       [Aviso, K.B., Yu, K.D., Lee, J.-Y., Tan, R.R.]   \n",
      "..                                                 ...   \n",
      "289  [Migo-Sumagang, Maria Victoria, Tan, Raymond R...   \n",
      "290  [Tapia, John Frederick D., Evangelista, Daniel...   \n",
      "291  [Teng, Sin Yong, Orosz, Ákos, How, Bing Shen, ...   \n",
      "292  [Pimentel, Jean, Aboagye, Emmanuel, Orosz, Áko...   \n",
      "293                     [Lee, Seungkwon, Park, Sunwon]   \n",
      "\n",
      "                              secondary_title  \\\n",
      "0          Cleaner Engineering and Technology   \n",
      "1          Computers and Chemical Engineering   \n",
      "2               Journal of Cleaner Production   \n",
      "3          Computers and Chemical Engineering   \n",
      "4          Cleaner Engineering and Technology   \n",
      "..                                        ...   \n",
      "289         Chemical Engineering Transactions   \n",
      "290         Chemical Engineering Transactions   \n",
      "291  Chemical Engineering Research and Design   \n",
      "292          Computers & Chemical Engineering   \n",
      "293          Computers & Chemical Engineering   \n",
      "\n",
      "                                              abstract         date  year  \\\n",
      "0    The challenges to commercialize biomass indust...      2022///  2022   \n",
      "1    Heat exchanger networks in real industrial pro...      2022///  2022   \n",
      "2    Improving the rational use of water and energy...      2022///  2022   \n",
      "3    Herein, the formula proposed for quantifying t...      2022///  2022   \n",
      "4    Input-output analysis is used for modelling ec...      2022///  2022   \n",
      "..                                                 ...          ...   ...   \n",
      "289  There is utmost urgency to decarbonize the var...  2022/09/01/  2022   \n",
      "290  Process integration is a technique that allows...  2022/09/01/  2022   \n",
      "291  P-graph is a popularly used framework for proc...    2022/12//  2022   \n",
      "292  Designing effective wastewater treatment netwo...    2022/11//  2022   \n",
      "293  The objective of this paper is to propose a me...    1996/01//  1996   \n",
      "\n",
      "                                   doi volume  \\\n",
      "0           10.1016/j.clet.2022.100554     10   \n",
      "1    10.1016/j.compchemeng.2022.107949    166   \n",
      "2        10.1016/j.jclepro.2022.133373    369   \n",
      "3    10.1016/j.compchemeng.2022.107932    165   \n",
      "4           10.1016/j.clet.2022.100510      9   \n",
      "..                                 ...    ...   \n",
      "289                 10.3303/CET2294005     94   \n",
      "290                 10.3303/CET2294193     94   \n",
      "291        10.1016/j.cherd.2022.09.043    188   \n",
      "292  10.1016/j.compchemeng.2022.108034    167   \n",
      "293       10.1016/0098-1354(96)00044-0     20   \n",
      "\n",
      "                             alternate_title1  ...          access_date  \\\n",
      "0                        Clean. Eng. Technol.  ...                  NaN   \n",
      "1                          Comput. Chem. Eng.  ...                  NaN   \n",
      "2                             J. Clean. Prod.  ...                  NaN   \n",
      "3                          Comput. Chem. Eng.  ...                  NaN   \n",
      "4                        Clean. Eng. Technol.  ...                  NaN   \n",
      "..                                        ...  ...                  ...   \n",
      "289                                       NaN  ...          2022/09/06/   \n",
      "290                                       NaN  ...          2022/09/06/   \n",
      "291  Chemical Engineering Research and Design  ...  2022/12/19/12:19:50   \n",
      "292          Computers & Chemical Engineering  ...  2022/12/19/12:21:15   \n",
      "293          Computers & Chemical Engineering  ...  2023/02/03/12:38:09   \n",
      "\n",
      "    subsidiary_authors tertiary_title tertiary_authors custom1  \\\n",
      "0                  NaN            NaN              NaN     NaN   \n",
      "1                  NaN            NaN              NaN     NaN   \n",
      "2                  NaN            NaN              NaN     NaN   \n",
      "3                  NaN            NaN              NaN     NaN   \n",
      "4                  NaN            NaN              NaN     NaN   \n",
      "..                 ...            ...              ...     ...   \n",
      "289                NaN            NaN              NaN     NaN   \n",
      "290                NaN            NaN              NaN     NaN   \n",
      "291                NaN            NaN              NaN     NaN   \n",
      "292                NaN            NaN              NaN     NaN   \n",
      "293                NaN            NaN              NaN     NaN   \n",
      "\n",
      "    accession_number   database_provider place_published unknown_tag  \\\n",
      "0                NaN                 NaN             NaN         NaN   \n",
      "1                NaN                 NaN             NaN         NaN   \n",
      "2                NaN                 NaN             NaN         NaN   \n",
      "3                NaN                 NaN             NaN         NaN   \n",
      "4                NaN                 NaN             NaN         NaN   \n",
      "..               ...                 ...             ...         ...   \n",
      "289              NaN                 NaN             NaN         NaN   \n",
      "290              NaN                 NaN             NaN         NaN   \n",
      "291              NaN  DOI.org (Crossref)             NaN         NaN   \n",
      "292              NaN  DOI.org (Crossref)             NaN         NaN   \n",
      "293              NaN  DOI.org (Crossref)             NaN         NaN   \n",
      "\n",
      "                                           short_title  \n",
      "0                                                  NaN  \n",
      "1                                                  NaN  \n",
      "2                                                  NaN  \n",
      "3                                                  NaN  \n",
      "4                                                  NaN  \n",
      "..                                                 ...  \n",
      "289                                                NaN  \n",
      "290                                                NaN  \n",
      "291  Framework to embed machine learning algorithms...  \n",
      "292                                                NaN  \n",
      "293                                                NaN  \n",
      "\n",
      "[294 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the first and last items of the df for illustrative purpose\n",
    "print(slr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(294, 32)\n",
      "['type_of_reference', 'title', 'authors', 'secondary_title', 'abstract', 'date', 'year', 'doi', 'volume', 'alternate_title1', 'language', 'issn', 'url', 'name_of_database', 'notes', 'keywords', 'number', 'start_page', 'end_page', 'publisher', 'secondary_authors', 'custom3', 'access_date', 'subsidiary_authors', 'tertiary_title', 'tertiary_authors', 'custom1', 'accession_number', 'database_provider', 'place_published', 'unknown_tag', 'short_title']\n"
     ]
    }
   ],
   "source": [
    "# Extract information of DF - (1) dimensions of DF; (2) list of headers \n",
    "print(slr_results.shape)\n",
    "print(slr_results.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to Excel for easier readability\n",
    "excel_writer = pd.ExcelWriter('SLR_Library.xlsx')\n",
    "slr_results.to_excel(excel_writer)\n",
    "excel_writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional step: Sorting the SLR_results dataframe by keywords defined based on previous knowledge. Sign \"|\" can be used to define several keywords as sort parameters in the title, abstract, and keywords (or other) fields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [type_of_reference, title, authors, secondary_title, abstract, date, year, doi, volume, alternate_title1, language, issn, url, name_of_database, notes, keywords, number, start_page, end_page, publisher, secondary_authors, custom3, access_date, subsidiary_authors, tertiary_title, tertiary_authors, custom1, accession_number, database_provider, place_published, unknown_tag, short_title]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "slr_results_filter1 = slr_results[\n",
    "slr_results['title'].str.contains('keyword1|keyword2|keyword3', case=False, na=False) |\n",
    "slr_results['abstract'].str.contains('keyword1|keyword2|keyword3', case=False, na=False) |\n",
    "slr_results['keywords'].str.contains('keyword1|keyword2|keyword3', case=False, na=False)\n",
    "]\n",
    "\n",
    "print(slr_results_filter1)\n",
    "\n",
    "# Writing to Excel for easier readability\n",
    "excel_writer = pd.ExcelWriter('slr_Library_filter1.xlsx')\n",
    "slr_results_filter1.to_excel(excel_writer)\n",
    "excel_writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
